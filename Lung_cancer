#Import needed libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

dataset = pd.read_csv('Lung_cancer.csv')

dataset


# Display the number of rows and columns in the dataset ( rows × columns)
dataset.shape


#Display all the columns
dataset.columns


# Display summary statistics (count, mean, std, min, quartiles, max) for all numeric columns in the dataset
dataset.describe()


# dataset.head() shows the first five rows of the dataset.
dataset.head()


# Display the last 3 rows only
dataset.tail(3)


# Display number of Ages without any duplicate values
len(dataset['AGE'].unique())


# Extract independent variables (features) and dependent variable (target)
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values
print(X)
print(y)


# Split the dataset into training and testing sets (75% train, 25% test) with reproducible random state
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)


# 1) split features/target
y = dataset['LUNG_CANCER']
X = dataset.drop(columns=['LUNG_CANCER'])         

# 2) keep only numeric columns 
num_cols = X.select_dtypes(include='number').columns
X = X[num_cols]

# 3) split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=0, stratify=y
)

# 4) scale
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test  = sc.transform(X_test)


# Train a K-Nearest Neighbors (KNN) classifier using 7 neighbors and Euclidean distance (p=2)
from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors = 7, metric = 'minkowski', p = 2)
classifier.fit(X_train, y_train)


# 1. Import libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score

# 2. Train the Random Forest model
clf = RandomForestClassifier(
    n_estimators=200,       # number of trees
    random_state=42,        # reproducibility
    class_weight='balanced' # handle class imbalance
)
clf.fit(X_train, y_train)

# 3. Predict the dependent variable (lung cancer YES/NO)
y_pred = clf.predict(X_test)

# 4. Evaluate the model
cm = confusion_matrix(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

# 5. ROC AUC (probability-based evaluation)
y_proba = clf.predict_proba(X_test)[:, 1]
roc_auc = roc_auc_score(y_test, y_proba)

# 6. Print results
print("Confusion Matrix:\n", cm)
print("\nAccuracy Score:", acc)
print("\nClassification Report:\n", report)
print("\nROC AUC Score:", roc_auc)


# Model Building and Confusion Matrix Only

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Train the Random Forest model
clf = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')
clf.fit(X_train, y_train)

# 2. Make predictions
y_pred = clf.predict(X_test)

# 3. Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

# 4. Visualize Confusion Matrix
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicted NO', 'Predicted YES'],
            yticklabels=['Actual NO', 'Actual YES'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()


from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)


from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, accuracy_score

# Step 1: Load dataset
df = pd.read_csv("lung_cancer.csv")

# Step 2: Encode target variable
df['LUNG_CANCER'] = df['LUNG_CANCER'].map({'NO': 0, 'YES': 1})

# Step 3: Select features and target
X = df[['AGE', 'SMOKING']]  # Example features — you can add more
y = df['LUNG_CANCER']

# Step 4: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)

# Step 5: Scale features
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# Step 6: Train classifier
classifier = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p=2)
classifier.fit(X_train, y_train)

# Step 7: Predict
y_pred = classifier.predict(X_test)

# Step 8: Confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Step 9: Plot confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,
            xticklabels=['Predicted NO', 'Predicted YES'],
            yticklabels=['Actual NO', 'Actual YES'])

plt.title('Confusion Matrix for Lung Cancer Prediction')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.tight_layout()
plt.show()

# Step 10: Accuracy
acc = accuracy_score(y_test, y_pred)
print("Accuracy:", acc)




# === Choose exactly TWO feature names from your dataset ===
# Example: feature_cols = ['mean radius', 'mean texture']
feature_cols = []  # <-- set to two valid column names from your DataFrame 'dataset'

# --- Safety checks and plotting ---
try:
    import matplotlib.pyplot as plt
    import numpy as np

    if isinstance(dataset, type(None)):
        raise NameError("It looks like 'dataset' is not defined. Make sure earlier cells loaded your DataFrame as 'dataset'.")
        
    if not feature_cols or len(feature_cols) != 2:
        print("Please set feature_cols to exactly two existing column names from 'dataset'. Example: ['f1','f2']")
    else:
        assert all(col in dataset.columns for col in feature_cols), "One or both chosen features are not in dataset.columns"
        X2 = dataset[feature_cols].values
        
        # Attempt to infer labels variable name from earlier sections
        # Prefer y if it exists; otherwise try last column as target
        try:
            y_true = y
        except NameError:
            y_true = dataset.iloc[:, -1].values
        
        # Create a scatter plot of the two features, colored by true labels
        plt.figure()
        plt.scatter(X2[:, 0], X2[:, 1], c=y_true)
        plt.xlabel(feature_cols[0])
        plt.ylabel(feature_cols[1])
        plt.title("Scatter of Two Selected Features (colored by TRUE labels)")
        plt.show()
        
        # Store for later reuse
        X_two_features = X2
        y_true_two = y_true
except Exception as e:
    print("Tip:", e)


from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import confusion_matrix, accuracy_score
import matplotlib.pyplot as plt

# Load dataset
df = pd.read_csv("lung_cancer.csv")

# Encode target variable
df['LUNG_CANCER'] = df['LUNG_CANCER'].map({'NO': 0, 'YES': 1})

# Select feature and target
X = df[['PEER_PRESSURE']]
y = df['LUNG_CANCER']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train decision tree
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_test)
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Accuracy Score:", accuracy_score(y_test, y_pred))

# Visualize tree
plt.figure(figsize=(10, 6))
plot_tree(model, feature_names=['PEER_PRESSURE'], class_names=['No Cancer', 'Cancer'], filled=True)
plt.title("Decision Tree: PEER_PRESSURE → LUNG_CANCER")
plt.show()


import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Display confusion matrix visually
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Cancer', 'Cancer'])
disp.plot(cmap='Blues')
plt.title("Confusion Matrix - Decision Tree Classification")
plt.show()


